# === Project Root ===
ROOT_DIR=$(cd "$(dirname "${BASH_SOURCE[0]}"/)" && pwd)
CURRENT_DATE_TIME=$(date +"%H-%M-%S_%m-%d-%Y")

# === Compliance & Prompt ===
COMPLIANCE=cmmc                                                # Compliance target (e.g., CMMC, HIPAA)
DEFAULT_PROMPTS_DIR=${ROOT_DIR}"/backend/coldrag/prompts/shared"         # Prompt directory location
DEFAULT_PROMPT_FILE=${DEFAULT_PROMPTS_DIR}"/blanket_compliance_prompt.txt"              # Default prompt template

# === Terraform Plan + State Inputs ===
PLAN_FILE=${ROOT_DIR}"/output/infra/terraform/binary/"${COMPLIANCE}"_tfplan_"$CURRENT_DATE_TIME".binary"           # Output of `terraform plan -out`
PLAN_JSON=${ROOT_DIR}"/output/infra/terraform/"${COMPLIANCE}"_tfplan.json"             # JSON-converted plan
STATE_JSON=${ROOT_DIR}"/output/infra/terraform/"${COMPLIANCE}".tfstate.json" # Optional: tfstate for deeper compliance context


# === Embedding Model Settings ===
EMBEDDING_MODEL=${ROOT_DIR}"/models/mpnet-finetuned"  # Local path to fine-tuned model
CHUNK_SIZE=1000                                                      # Token chunk size per doc
CHUNK_OVERLAP=100                                                    # Token overlap between chunks
SEARCH_K=10                                                          # Top K documents retrieved per query
SEARCH_TYPE=mmr                                                      # Options: mmr, similarity

# === LLM Settings ===
LLM_MODEL=mistral                                                    # Ollama model to use
LLM_RETURN_SOURCES=true
CHAIN_TYPE=stuff

# === Reference Documents for RAG ===
REFERENCE_DIR=#"/mnt/f/Cybersecurity Engineering/coldchainsecure/cold_rag"

# === Output Locations ===
OUTPUT_FILE=${ROOT_DIR}"/output/findings/compliance_violations.json"  # Final parsed output
HTML_OUTPUT=${ROOT_DIR}"/output/infra/terraform/summary/"${COMPLIANCE}"_infra_summary_"${CURRENT_DATE_TIME}".html"

# === pipeline & Toggles ===
RUN_TERRAFORM=true
TRAIN_MODEL=true
GENERATE_HTML=true
SETUP_VENV=true
INSTALL_REQUIREMENTS=true
CHECK_OLLAMA=true
OFFLINE_MODE=false
THEME=dark

# === Scripts & Binaries ===
TRAIN_MODEL_SCRIPT=${ROOT_DIR}"/backend/scripts/rag/pipeline/train_model.sh"
TERRAFORM_SCRIPT=${ROOT_DIR}"/backend/scripts/rag/pipeline/terraform_pipeline.sh"
RAG_INSPECTOR_SCRIPT=${ROOT_DIR}"/backend/scripts/rag/pipeline/run_rag_inspector.sh"
HTML_GEN_SCRIPT=${ROOT_DIR}"/backend/scripts/rag/pipeline/html_generation.sh"
OLLAMA_CHECK_SCRIPT=${ROOT_DIR}"/backend/scripts/rag/pipeline/ollama_check.sh"
SETUP_ENV_SCRIPT=${ROOT_DIR}"/backend/scripts/rag/setup_env.sh"
RAG_INSPECTOR_MODULE=${ROOT_DIR}"/backend/coldrag/rag_inspector.py"
TERRAFORM_HTML_REPORT=${ROOT_DIR}"/backend/scripts/infra/terraform_json_to_html.py"

# === Dependencies ===
VENV_PATH="venv"
REQUIREMENTS_FILE=${ROOT_DIR}"/backend/requirements.txt"

# === Training Resources ===
MODEL_NAME=sentence-transformers/all-mpnet-base-v2                  # HuggingFace base model for initial training
MODEL_OUTPUT_DIR=${ROOT_DIR}"/models/mpnet-finetuned"
TRAINING_DATA_PATH=${ROOT_DIR}"/backend/coldrag/train/training_pairs.py"
RETRAIN_MODEL=true

#=== API ===
START_FASTAPI=true
FASTAPI_PORT=8000
FASTAPI_HOST=127.0.0.1


